#!/usr/bin/env python
# coding=utf-8
'''
Description  : OSSæ•°æ®è¿ç§»å·¥å…·ï¼ˆå‘½ä»¤è¡Œå‚æ•°ç‰ˆï¼‰
'''
import sys
import os
import time
import re
import threading
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
import oss2
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv('.env')

RETRY_TIMES = 3
THROTTLE_DELAY = 2
STATS_INTERVAL = 5
MAX_WORKERS = int(os.getenv('MAX_WORKERS', '20'))
PAGE_SIZE = int(os.getenv('PAGE_SIZE', '500'))
SKIP_EXISTS = False

# å…¨å±€çŠ¶æ€ï¼ˆçº¿ç¨‹å®‰å…¨æ§åˆ¶ï¼‰
counter_lock = threading.Lock()
log_lock = threading.Lock()
copied = 0
skipped = 0
errors = 0

def format_path(path):
    """ç»Ÿä¸€è·¯å¾„æ ¼å¼"""
    return path if path.endswith('/') else path + '/'

def parse_oss_uri(uri):
    """è§£æOSS URIæ ¼å¼ï¼šoss://bucket-name/path/prefix/"""
    pattern = r'^oss://([^/]+)/(.*)$'
    match = re.match(pattern, uri)
    if not match:
        raise ValueError(f"æ— æ•ˆçš„OSSè·¯å¾„æ ¼å¼: {uri}")

    bucket_name = match.group(1)
    prefix = format_path(match.group(2) or '')
    return bucket_name, prefix

def get_total_objects(bucket, prefix):
    """é¢„ç»Ÿè®¡æœ‰æ•ˆå¯¹è±¡æ€»æ•°"""
    print("ğŸ”„ æ­£åœ¨ç»Ÿè®¡è¿ç§»å¯¹è±¡æ€»æ•°...")
    total = 0
    marker = ''

    while True:
        result = bucket.list_objects(
            prefix=prefix,
            marker=marker,
            max_keys=PAGE_SIZE
        )

        valid_objs = [obj for obj in result.object_list if not obj.key.endswith('/')]
        total += len(valid_objs)

        if result.is_truncated:
            marker = result.next_marker
        else:
            break

    print(f"âœ… å¾…è¿ç§»å¯¹è±¡æ€»æ•°: {total}")
    return total

def process_object(obj, dest_bucket, src_bucket_name, src_prefix, dest_prefix, s_log, f_log):
    global copied, skipped, errors
    src_key = obj.key

    # ç”Ÿæˆç›®æ ‡è·¯å¾„
    dest_key = src_key.replace(src_prefix, dest_prefix, 1)

    # è·³è¿‡æ¡ä»¶1: ç›®æ ‡å·²å­˜åœ¨ç›¸åŒè·¯å¾„æ–‡ä»¶
    if SKIP_EXISTS:
        if dest_bucket.object_exists(dest_key):
            with counter_lock:
                skipped += 1
            with log_lock:
                s_log.write(f"[SKIP][{time.ctime()}] {dest_key}\n")
            return

    # è·³è¿‡ç›¸åŒè·¯å¾„
    if src_key == dest_key:
        with counter_lock:
            skipped += 1
        with log_lock:
            s_log.write(f"[SKIP][{time.ctime()}] {src_key}\n")
        return

    # å¸¦é‡è¯•çš„æ‹·è´æ“ä½œ
    for attempt in range(1, RETRY_TIMES+1):
        try:
            dest_bucket.copy_object(
                src_bucket_name,
                src_key,
                dest_key
            )
            with counter_lock:
                copied += 1
            with log_lock:
                s_log.write(f"[SUCCESS][{time.ctime()}] {src_key} -> {dest_key}\n")
            return
        except oss2.exceptions.OssError as e:
            if e.status == 429:  # æµé‡æ§åˆ¶
                time.sleep(THROTTLE_DELAY * attempt)
                continue
            with counter_lock:
                errors += 1
            with log_lock:
                f_log.write(f"[ATTEMPT {attempt}/{RETRY_TIMES}][{time.ctime()}] {src_key} | {str(e)}\n")
            if attempt == RETRY_TIMES:
                f_log.write(f"[FINAL FAIL][{time.ctime()}] {src_key}\n")

def print_progress(start_time, total_objects):
    """å®šæ—¶è¾“å‡ºè¿›åº¦ä¿¡æ¯"""
    while True:
        processed = copied + skipped + errors
        if total_objects > 0:
            progress = processed / total_objects * 100
            elapsed = time.time() - start_time
            speed = processed / elapsed if elapsed > 0 else 0
            remaining = (total_objects - processed) / speed if speed > 0 else 0

            status = (
                f"ğŸš€ è¿›åº¦: {processed}/{total_objects} ({progress:.1f}%) | "
                f"é€Ÿåº¦: {speed:.1f} obj/s | "
                f"ç”¨æ—¶: {elapsed:.0f}s | "
                f"å‰©ä½™: {remaining:.0f}s"
            )
        else:
            status = f"ğŸ”„ å·²å¤„ç†: {processed} å¯¹è±¡"

        print(status, end='\r')
        time.sleep(STATS_INTERVAL)

def copy_objects(src_bucket, dest_bucket, src_prefix, dest_prefix, success_log, fail_log):
    global copied, skipped, errors
    copied = skipped = errors = 0
    marker = ''
    start_time = time.time()

    # è·å–æ€»æ•°
    total_objects = get_total_objects(src_bucket, src_prefix)

    # å¯åŠ¨è¿›åº¦çº¿ç¨‹
    stats_thread = threading.Thread(
        target=print_progress,
        args=(start_time, total_objects),
        daemon=True
    )
    stats_thread.start()

    with open(success_log, 'a') as s_log, open(fail_log, 'a') as f_log:
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            while True:
                result = src_bucket.list_objects(
                    prefix=src_prefix,
                    marker=marker,
                    max_keys=PAGE_SIZE
                )

                if not result.object_list:
                    break

                # æäº¤æœ¬é¡µä»»åŠ¡
                futures = [
                    executor.submit(
                        process_object,
                        obj,
                        dest_bucket,
                        src_bucket.bucket_name,
                        src_prefix,
                        dest_prefix,
                        s_log,
                        f_log
                    )
                    for obj in result.object_list
                    if not obj.key.endswith('/')
                ]

                # ç­‰å¾…æœ¬é¡µå®Œæˆ
                for _ in as_completed(futures):
                    pass

                # æ›´æ–°åˆ†é¡µæ ‡è®°
                marker = result.next_marker if result.is_truncated else None
                if not marker:
                    break

    # è¾“å‡ºæŠ¥å‘Š
    print("\n" + "="*50)
    print(f"æ€»å¤„ç†å¯¹è±¡: {copied + skipped + errors}")
    print(f"âœ… æˆåŠŸå¤åˆ¶: {copied} (æˆåŠŸç‡: {copied/(copied+errors or 1):.1%})")
    print(f"â­ï¸ è‡ªåŠ¨è·³è¿‡: {skipped}")
    print(f"âŒ æœ€ç»ˆå¤±è´¥: {errors}")
    print(f"â±ï¸ æ€»è€—æ—¶: {time.time()-start_time:.1f}ç§’")
    print(f"ğŸ“œ æˆåŠŸæ—¥å¿—: {success_log}")
    print(f"ğŸ“„ é”™è¯¯æ—¥å¿—: {fail_log}")
    print("="*50)

    return total_objects

if __name__ == '__main__':
    # é…ç½®å‚æ•°
    parser = argparse.ArgumentParser(description='OSSæ•°æ®è¿ç§»å·¥å…·')
    parser.add_argument('--src', required=True, help='æºè·¯å¾„ï¼Œæ ¼å¼ï¼šoss://bucket/path/')
    parser.add_argument('--dest', required=True, help='ç›®æ ‡è·¯å¾„ï¼Œæ ¼å¼ï¼šoss://bucket/path/')
    parser.add_argument('--page-size', type=int, default=500, help='åˆ†é¡µå¤§å°ï¼ˆé»˜è®¤ï¼š500ï¼‰')
    parser.add_argument('--workers', type=int, default=20, help='å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š20ï¼‰')
    parser.add_argument('--skip-exists', type=bool, default=False, help='ç›®æ ‡å­˜åœ¨æ—¶å¿½ç•¥ï¼ˆé»˜è®¤ï¼šFalseï¼‰')
    args = parser.parse_args()

    # è§£æé…ç½®
    if args.page_size:
        PAGE_SIZE = int(args.page_size)
    if args.workers:
        MAX_WORKERS = int(args.workers)
    if (args.skip_exists):
        SKIP_EXISTS = True

    # è§£æOSSè·¯å¾„
    try:
        src_bucket_name, src_prefix = parse_oss_uri(args.src)
        dest_bucket_name, dest_prefix = parse_oss_uri(args.dest)
    except ValueError as e:
        print(f"é”™è¯¯: {str(e)}")
        sys.exit(1)

    # åˆå§‹åŒ–OSSå®¢æˆ·ç«¯
    auth = oss2.Auth(
        os.getenv('OSS_ACCESS_KEY_ID'),
        os.getenv('OSS_ACCESS_KEY_SECRET')
    )
    endpoint = os.getenv('OSS_ENDPOINT', 'https://oss-cn-hangzhou.aliyuncs.com')

    src_bucket = oss2.Bucket(auth, endpoint, src_bucket_name)
    dest_bucket = oss2.Bucket(auth, endpoint, dest_bucket_name)

    # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶å
    log_prefix = f"{src_bucket_name}#{src_prefix.replace('/', '_')}to_{dest_bucket_name}#{dest_prefix.replace('/', '_')}"
    success_log = f"logs/{log_prefix}success.log"
    fail_log = f"logs/{log_prefix}fail.log"

    # æ‰“å°é…ç½®
    print("\nğŸ”§ è¿ç§»é…ç½®:")
    print(f"æºè·¯å¾„: oss://{src_bucket_name}/{src_prefix}")
    print(f"ç›®æ ‡è·¯å¾„: oss://{dest_bucket_name}/{dest_prefix}")
    print(f"åˆ†é¡µå¤§å°: {PAGE_SIZE}")
    print(f"å¹¶å‘çº¿ç¨‹: {MAX_WORKERS}")
    print(f"æ—¥å¿—æ–‡ä»¶: {success_log} å’Œ {fail_log}\n")

    total_objects = 0

    # æ‰§è¡Œè¿ç§»
    try:
        total_objects = copy_objects(
            src_bucket=src_bucket,
            dest_bucket=dest_bucket,
            src_prefix=src_prefix,
            dest_prefix=dest_prefix,
            success_log=success_log,
            fail_log=fail_log
        )
    except KeyboardInterrupt:
        print("\nâš ï¸ æ“ä½œå·²ä¸­æ–­ï¼æ­£åœ¨ä¿å­˜çŠ¶æ€...")
        processed = copied + skipped + errors
        if total_objects > 0:
            print(f"å½“å‰è¿›åº¦: {processed}/{total_objects} ({processed/total_objects*100:.1f}%)")
    finally:
        print("è¿ç§»è¿›ç¨‹ç»“æŸ")
